{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAE4EmJ0d9yZ"
      },
      "source": [
        "#Jukebox notebook with autosaving.\n",
        "\n",
        "Speed upsampling supported. Switch to upsample mode will happen automatically if data file is detected within the folder provided.\n",
        "\n",
        "Colab Pro users can use the 5b_lyrics (or 5b) model.\n",
        "Free users can also use the 5b_lyrics (or 5b) model, if they are assigned a Tesla T4 GPU. If assigned a Tesla K80, the weaker 1b_lyrics model is recommended.\n",
        "\n",
        "Join the Jukebox community at https://discord.gg/aEqXFN9amV\n",
        "\n",
        "This Notebook Was edited by Yo Jeremijenko-Conley to generate music for a project for MUSIGR6610 - SOUND: ADVANCED TOPICS at Columbia University"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qEqdj8u0gdN",
        "outputId": "892ef9ed-0cea-46e5-e999-ffcaef004a61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-62e599f3-654a-1ad9-f5c7-1737ca6595a6)\n"
          ]
        }
      ],
      "source": [
        "#@title Check which GPU you were assigned by running this cell.\n",
        "!nvidia-smi -L\n",
        "your_lyrics = \"\"\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoXdBHkX4d1j"
      },
      "outputs": [],
      "source": [
        "your_lyrics = \"\"\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHPjHa9k6NTE"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAdFGF-bqVMY",
        "outputId": "6bfb93d8-b8c8-4929-9ae4-6db85a058071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/craftmine1000/jukebox-saveopt.git\n",
            "  Cloning https://github.com/craftmine1000/jukebox-saveopt.git to /tmp/pip-req-build-xbd4n5s7\n",
            "  Running command git clone -q https://github.com/craftmine1000/jukebox-saveopt.git /tmp/pip-req-build-xbd4n5s7\n",
            "Collecting fire==0.1.3\n",
            "  Downloading fire-0.1.3.tar.gz (33 kB)\n",
            "Collecting tqdm==4.45.0\n",
            "  Downloading tqdm-4.45.0-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting soundfile==0.10.3.post1\n",
            "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
            "Collecting unidecode==1.1.1\n",
            "  Downloading Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 29.6 MB/s \n",
            "\u001b[?25hCollecting numba==0.48.0\n",
            "  Downloading numba-0.48.0-1-cp38-cp38-manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 70.2 MB/s \n",
            "\u001b[?25hCollecting librosa==0.7.2\n",
            "  Downloading librosa-0.7.2.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 85.6 MB/s \n",
            "\u001b[?25hCollecting mpi4py>=3.0.0\n",
            "  Downloading mpi4py-3.1.4.tar.gz (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 56.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire==0.1.3->jukebox==1.0) (1.15.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->jukebox==1.0) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.2.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->jukebox==1.0) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->jukebox==1.0) (0.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba==0.48.0->jukebox==1.0) (57.4.0)\n",
            "Collecting llvmlite<0.32.0,>=0.31.0dev0\n",
            "  Downloading llvmlite-0.31.0-cp38-cp38-manylinux1_x86_64.whl (20.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2 MB 11.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile==0.10.3.post1->jukebox==1.0) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile==0.10.3.post1->jukebox==1.0) (2.21)\n",
            "Collecting resampy>=0.2.2\n",
            "  Downloading resampy-0.4.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 76.4 MB/s \n",
            "\u001b[?25h  Downloading resampy-0.4.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 94.3 MB/s \n",
            "\u001b[?25h  Downloading resampy-0.3.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 90.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.7.2->jukebox==1.0) (3.1.0)\n",
            "Building wheels for collected packages: jukebox, fire, librosa, mpi4py\n",
            "  Building wheel for jukebox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jukebox: filename=jukebox-1.0-py3-none-any.whl size=200283 sha256=5591d19ed944994a7fbaf88ee2cfaef5c60238347186b4fb686d0ba27271f28b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i09use0u/wheels/a5/2a/7d/9c80d3ce7d9b0571e4bbfaee1dbcd1519deade8e56fe5fa1d7\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.1.3-py2.py3-none-any.whl size=49718 sha256=428a4bda371d18693fc006251f6051499d9f0a9a9a56bbb13c55e26bde17298f\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/8f/7a/f2ab65f4cbe021062840cd15ed1393f979d4ebb5fd2971a37b\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.7.2-py3-none-any.whl size=1612903 sha256=b77e4054ffd17a1a3da4a0b6428f7fb52c3c541c5a87c471c65d92a4db3b2379\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/f0/b0/a8f9944f274bbc0f0159f2268f43dadcfa1cfe50a9007d8e1f\n",
            "  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.4-cp38-cp38-linux_x86_64.whl size=4438418 sha256=c19f156186a6f7e14466ed912e6ac4e28f989383c23fd491485af8bceab1513d\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/35/48/0b9a7076995eea5ea64a7e4bc3f0f342f453080795276264e7\n",
            "Successfully built jukebox fire librosa mpi4py\n",
            "Installing collected packages: llvmlite, numba, soundfile, resampy, unidecode, tqdm, mpi4py, librosa, fire, jukebox\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.4\n",
            "    Uninstalling numba-0.56.4:\n",
            "      Successfully uninstalled numba-0.56.4\n",
            "  Attempting uninstall: soundfile\n",
            "    Found existing installation: soundfile 0.11.0\n",
            "    Uninstalling soundfile-0.11.0:\n",
            "      Successfully uninstalled soundfile-0.11.0\n",
            "  Attempting uninstall: resampy\n",
            "    Found existing installation: resampy 0.4.2\n",
            "    Uninstalling resampy-0.4.2:\n",
            "      Successfully uninstalled resampy-0.4.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.1\n",
            "    Uninstalling tqdm-4.64.1:\n",
            "      Successfully uninstalled tqdm-4.64.1\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.8.1\n",
            "    Uninstalling librosa-0.8.1:\n",
            "      Successfully uninstalled librosa-0.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.45.0 which is incompatible.\u001b[0m\n",
            "Successfully installed fire-0.1.3 jukebox-1.0 librosa-0.7.2 llvmlite-0.31.0 mpi4py-3.1.4 numba-0.48.0 resampy-0.3.1 soundfile-0.10.3.post1 tqdm-4.45.0 unidecode-1.1.1\n",
            "Using cuda True\n",
            "Tesla T4 detected, max_batch_size set to 2\n",
            "Downloading from azure\n",
            "Running  wget -O /root/.cache/jukebox/models/5b/vqvae.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b/vqvae.pth.tar\n",
            "Restored from /root/.cache/jukebox/models/5b/vqvae.pth.tar\n",
            "0: Loading vqvae in eval mode\n",
            "Loading artist IDs from /usr/local/lib/python3.8/dist-packages/jukebox/data/ids/v2_artist_ids.txt\n",
            "Loading artist IDs from /usr/local/lib/python3.8/dist-packages/jukebox/data/ids/v2_genre_ids.txt\n",
            "Level:2, Cond downsample:None, Raw to tokens:128, Sample length:1048576\n",
            "Downloading from azure\n",
            "Running  wget -O /root/.cache/jukebox/models/5b/prior_level_2.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b/prior_level_2.pth.tar\n",
            "Restored from /root/.cache/jukebox/models/5b/prior_level_2.pth.tar\n",
            "0: Loading prior in eval mode\n",
            "mode is now primed\n",
            "Tesla T4 detected, lower_batch_size set to 12\n",
            "Sampling level 2\n",
            "\n",
            "Sampling 8192 tokens for [0,8192]. Conditioning on 2067 tokens\n",
            "Primed sampling 2 samples with temp=0.96, top_k=0, top_p=0.0\n",
            "130/130 [0:00:12<0:00:00, 10.47it/s]    \n",
            "6125/6125 [07:24<00:00, 13.79it/s]\n",
            "progress saved\n",
            "\n",
            "WAV written to disk\n",
            "\n",
            "1/2 [0:07:37<0:07:37, 457.17s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [76,8268]. Conditioning on 8116 tokens\n",
            "Primed sampling 2 samples with temp=0.96, top_k=0, top_p=0.0\n",
            "508/508 [0:01:00<0:00:00, 5.6it/s]    \n",
            "76/76 [00:06<00:00, 12.27it/s]\n",
            "progress saved\n",
            "\n",
            "2/2 [0:08:44<0:00:00, 66.93s/it]    \n",
            "Conditioning on 1 above level(s)\n",
            "Checkpointing convs\n",
            "Checkpointing convs\n",
            "Loading artist IDs from /usr/local/lib/python3.8/dist-packages/jukebox/data/ids/v2_artist_ids.txt\n",
            "Loading artist IDs from /usr/local/lib/python3.8/dist-packages/jukebox/data/ids/v2_genre_ids.txt\n",
            "Level:0, Cond downsample:4, Raw to tokens:8, Sample length:65536\n",
            "Downloading from azure\n",
            "Running  wget -O /root/.cache/jukebox/models/5b/prior_level_0.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b/prior_level_0.pth.tar\n",
            "Restored from /root/.cache/jukebox/models/5b/prior_level_0.pth.tar\n",
            "0: Loading prior in eval mode\n",
            "Conditioning on 1 above level(s)\n",
            "Checkpointing convs\n",
            "Checkpointing convs\n",
            "Loading artist IDs from /usr/local/lib/python3.8/dist-packages/jukebox/data/ids/v2_artist_ids.txt\n",
            "Loading artist IDs from /usr/local/lib/python3.8/dist-packages/jukebox/data/ids/v2_genre_ids.txt\n",
            "Level:1, Cond downsample:4, Raw to tokens:32, Sample length:262144\n",
            "Downloading from azure\n",
            "Running  wget -O /root/.cache/jukebox/models/5b/prior_level_1.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b/prior_level_1.pth.tar\n",
            "Restored from /root/.cache/jukebox/models/5b/prior_level_1.pth.tar\n",
            "0: Loading prior in eval mode\n",
            "Sampling level 1\n",
            "\n",
            "Sampling 8192 tokens for [0,8192]. Conditioning on 8192 tokens\n",
            "\n",
            "WAV written to disk\n",
            "\n",
            "1/8 [0:00:00<0:00:01, 6.89it/s]    \n",
            "Sampling 8192 tokens for [4096,12288]. Conditioning on 4172 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "131/131 [0:00:11<0:00:00, 11.48it/s]    \n",
            "4020/4020 [04:15<00:00, 15.74it/s]\n",
            "progress saved\n",
            "\n",
            "2/8 [0:04:28<0:26:45, 267.55s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [8192,16384]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 11.7it/s]    \n",
            "4096/4096 [04:19<00:00, 15.80it/s]\n",
            "progress saved\n",
            "\n",
            "3/8 [0:08:59<0:22:37, 271.36s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [12288,20480]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 12.01it/s]    \n",
            "4096/4096 [04:19<00:00, 15.78it/s]\n",
            "progress saved\n",
            "\n",
            "4/8 [0:13:30<0:18:05, 271.27s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [16384,24576]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 11.61it/s]    \n",
            "4096/4096 [04:21<00:00, 15.66it/s]\n",
            "progress saved\n",
            "\n",
            "5/8 [0:18:04<0:13:40, 273.47s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [20480,28672]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 12.16it/s]    \n",
            "4096/4096 [04:21<00:00, 15.69it/s]\n",
            "progress saved\n",
            "\n",
            "6/8 [0:22:37<0:09:06, 272.93s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [24576,32768]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 12.29it/s]    \n",
            "4096/4096 [04:20<00:00, 15.75it/s]\n",
            "progress saved\n",
            "\n",
            "7/8 [0:27:09<0:04:32, 271.86s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [24880,33072]. Conditioning on 7888 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "247/247 [0:00:21<0:00:00, 11.26it/s]    \n",
            "304/304 [00:19<00:00, 15.73it/s]\n",
            "progress saved\n",
            "\n",
            "8/8 [0:27:50<0:00:00, 41.29s/it]    \n",
            "Sampling level 0\n",
            "\n",
            "Sampling 8192 tokens for [0,8192]. Conditioning on 8192 tokens\n",
            "\n",
            "WAV written to disk\n",
            "\n",
            "1/32 [0:00:00<0:00:08, 4.04it/s]    \n",
            "Sampling 8192 tokens for [4096,12288]. Conditioning on 8192 tokens\n",
            "\n",
            "2/32 [0:00:00<0:00:00, 454.03it/s]    \n",
            "Sampling 8192 tokens for [8192,16384]. Conditioning on 8192 tokens\n",
            "\n",
            "3/32 [0:00:00<0:00:00, 717.34it/s]    \n",
            "Sampling 8192 tokens for [12288,20480]. Conditioning on 8192 tokens\n",
            "\n",
            "4/32 [0:00:00<0:00:00, 565.96it/s]    \n",
            "Sampling 8192 tokens for [16384,24576]. Conditioning on 8192 tokens\n",
            "\n",
            "5/32 [0:00:00<0:00:00, 475.92it/s]    \n",
            "Sampling 8192 tokens for [20480,28672]. Conditioning on 8192 tokens\n",
            "\n",
            "6/32 [0:00:00<0:00:00, 538.15it/s]    \n",
            "Sampling 8192 tokens for [24576,32768]. Conditioning on 8192 tokens\n",
            "\n",
            "7/32 [0:00:00<0:00:00, 756.28it/s]    \n",
            "Sampling 8192 tokens for [28672,36864]. Conditioning on 4400 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "138/138 [0:00:12<0:00:00, 11.58it/s]    \n",
            "3792/3792 [03:59<00:00, 15.80it/s]\n",
            "progress saved\n",
            "\n",
            "8/32 [0:04:13<1:41:07, 252.81s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [32768,40960]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 12.11it/s]    \n",
            "4096/4096 [04:11<00:00, 16.31it/s]\n",
            "progress saved\n",
            "\n",
            "9/32 [0:08:36<1:40:45, 262.82s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [36864,45056]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 11.11it/s]    \n",
            "4096/4096 [04:16<00:00, 15.99it/s]\n",
            "progress saved\n",
            "\n",
            "10/32 [0:13:04<1:38:13, 267.85s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [40960,49152]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 12.27it/s]    \n",
            "4096/4096 [04:13<00:00, 16.17it/s]\n",
            "progress saved\n",
            "\n",
            "WAV written to disk\n",
            "\n",
            "11/32 [0:17:29<1:32:56, 265.54s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [45056,53248]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 12.6it/s]    \n",
            "4096/4096 [04:14<00:00, 16.12it/s]\n",
            "progress saved\n",
            "\n",
            "12/32 [0:21:55<1:28:28, 265.41s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [49152,57344]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:10<0:00:00, 12.66it/s]    \n",
            "4096/4096 [04:16<00:00, 15.94it/s]\n",
            "progress saved\n",
            "\n",
            "13/32 [0:26:23<1:24:57, 268.26s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [53248,61440]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 11.78it/s]    \n",
            "4096/4096 [04:24<00:00, 15.46it/s]\n",
            "progress saved\n",
            "\n",
            "14/32 [0:31:00<1:23:07, 277.05s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [57344,65536]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 12.49it/s]    \n",
            "4096/4096 [04:20<00:00, 15.72it/s]\n",
            "progress saved\n",
            "\n",
            "15/32 [0:35:32<1:17:05, 272.08s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [61440,69632]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 11.02it/s]    \n",
            "4096/4096 [04:22<00:00, 15.61it/s]\n",
            "progress saved\n",
            "\n",
            "16/32 [0:40:06<1:13:10, 274.39s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [65536,73728]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 12.31it/s]    \n",
            "4096/4096 [04:22<00:00, 15.58it/s]\n",
            "progress saved\n",
            "\n",
            "17/32 [0:44:41<1:08:40, 274.65s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [69632,77824]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 12.07it/s]    \n",
            "4096/4096 [04:21<00:00, 15.67it/s]\n",
            "progress saved\n",
            "\n",
            "18/32 [0:49:14<1:03:44, 273.13s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [73728,81920]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 12.29it/s]    \n",
            "4096/4096 [04:22<00:00, 15.57it/s]\n",
            "progress saved\n",
            "\n",
            "19/32 [0:53:49<0:59:32, 274.74s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [77824,86016]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 11.92it/s]    \n",
            "4096/4096 [04:21<00:00, 15.65it/s]\n",
            "progress saved\n",
            "\n",
            "20/32 [0:58:23<0:54:45, 273.72s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [81920,90112]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 12.74it/s]    \n",
            "4096/4096 [04:18<00:00, 15.83it/s]\n",
            "progress saved\n",
            "\n",
            "WAV written to disk\n",
            "\n",
            "21/32 [1:02:54<0:49:39, 270.85s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [86016,94208]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 12.19it/s]    \n",
            "4096/4096 [04:19<00:00, 15.80it/s]\n",
            "progress saved\n",
            "\n",
            "22/32 [1:07:25<0:45:11, 271.07s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [90112,98304]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 12.56it/s]    \n",
            "4096/4096 [04:19<00:00, 15.81it/s]\n",
            "progress saved\n",
            "\n",
            "23/32 [1:11:56<0:40:38, 270.88s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [94208,102400]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 11.63it/s]    \n",
            "4096/4096 [04:22<00:00, 15.62it/s]\n",
            "progress saved\n",
            "\n",
            "24/32 [1:16:30<0:36:34, 274.25s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [98304,106496]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 12.02it/s]    \n",
            "4096/4096 [04:21<00:00, 15.66it/s]\n",
            "progress saved\n",
            "\n",
            "25/32 [1:21:03<0:31:54, 273.47s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [102400,110592]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 12.28it/s]    \n",
            "4096/4096 [04:21<00:00, 15.66it/s]\n",
            "progress saved\n",
            "\n",
            "26/32 [1:25:37<0:27:21, 273.42s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [106496,114688]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 11.96it/s]    \n",
            "4096/4096 [04:22<00:00, 15.63it/s]\n",
            "progress saved\n",
            "\n",
            "27/32 [1:30:11<0:22:50, 274.03s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [110592,118784]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 12.32it/s]    \n",
            "4096/4096 [04:29<00:00, 15.21it/s]\n",
            "progress saved\n",
            "\n",
            "28/32 [1:34:52<0:18:45, 281.34s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [114688,122880]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 11.86it/s]    \n",
            "4096/4096 [04:29<00:00, 15.19it/s]\n",
            "progress saved\n",
            "\n",
            "29/32 [1:39:34<0:14:05, 281.81s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [118784,126976]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 11.61it/s]    \n",
            "4096/4096 [04:29<00:00, 15.19it/s]\n",
            "progress saved\n",
            "\n",
            "30/32 [1:44:16<0:09:23, 281.67s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [122880,131072]. Conditioning on 4096 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [0:00:11<0:00:00, 12.09it/s]    \n",
            "4096/4096 [04:28<00:00, 15.23it/s]\n",
            "progress saved\n",
            "\n",
            "WAV written to disk\n",
            "\n",
            "31/32 [1:48:57<0:04:42, 281.75s/it]    \n",
            "progress loaded\n",
            "Sampling 8192 tokens for [124096,132288]. Conditioning on 6976 tokens\n",
            "Primed sampling 2 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "218/218 [0:00:19<0:00:00, 11.75it/s]    \n",
            "1216/1216 [01:19<00:00, 15.28it/s]\n",
            "progress saved\n",
            "\n",
            "32/32 [1:50:37<0:00:00, 99.66s/it]    \n"
          ]
        }
      ],
      "source": [
        "#@title Select your settings and run this cell to start generating\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!pip install --upgrade git+https://github.com/craftmine1000/jukebox-saveopt.git\n",
        "\n",
        "import jukebox\n",
        "import torch as t\n",
        "import librosa\n",
        "import os\n",
        "from IPython.display import Audio\n",
        "from jukebox.make_models import make_vqvae, make_prior, MODELS, make_model\n",
        "from jukebox.hparams import Hyperparams, setup_hparams\n",
        "from jukebox.sample import sample_single_window, _sample, \\\n",
        "                           sample_partial_window, upsample, \\\n",
        "                           load_prompts\n",
        "from jukebox.utils.dist_utils import setup_dist_from_mpi\n",
        "from jukebox.utils.torch_utils import empty_cache\n",
        "# MPI Connect. MPI doesn't like being initialized twice, hence the following\n",
        "try:\n",
        "    if device is not None:\n",
        "        pass\n",
        "except NameError:\n",
        "    rank, local_rank, device = setup_dist_from_mpi()\n",
        "\n",
        "model = \"5b\" #@param [\"5b_lyrics\", \"5b\", \"1b_lyrics\"]\n",
        "if model == '5b':\n",
        "  your_lyrics = \"\"\"\n",
        "  \"\"\"\n",
        "\n",
        "save_and_load_models_from_drive = False\n",
        "\n",
        "#START GDRIVE MODEL LOADER\n",
        "if save_and_load_models_from_drive == True:\n",
        "  import os.path\n",
        "  !apt install pv\n",
        "  !mkdir /root/.cache ; mkdir /root/.cache/jukebox ; mkdir /root/.cache/jukebox/models ; mkdir /root/.cache/jukebox/models/1b_lyrics ; mkdir /root/.cache/jukebox/models/5b_lyrics ; mkdir /root/.cache/jukebox/models/5b\n",
        "  !mkdir /content/gdrive/MyDrive/jukebox\n",
        "  !mkdir /content/gdrive/MyDrive/jukebox/models\n",
        "  !mkdir /content/gdrive/MyDrive/jukebox/models/5b\n",
        "  !mkdir /content/gdrive/MyDrive/jukebox/models/5b_lyrics\n",
        "  !mkdir /content/gdrive/MyDrive/jukebox/models/1b_lyrics\n",
        "\n",
        "\n",
        "def load_5b_vqvae():\n",
        "    if os.path.exists(\"/root/.cache/jukebox/models/5b/vqvae.pth.tar\") == False:\n",
        "      if os.path.exists(\"/content/gdrive/MyDrive/jukebox/models/5b/vqvae.pth.tar\") == False:\n",
        "        print(\"5b_vqvae not stored in Google Drive. Downloading for the first time.\")\n",
        "        !wget https://openaipublic.azureedge.net/jukebox/models/5b/vqvae.pth.tar -O /content/gdrive/MyDrive/jukebox/models/5b/vqvae.pth.tar\n",
        "      else:\n",
        "        print(\"5b_vqvae stored in Google Drive.\")\n",
        "      print('Copying 5b VQVAE')\n",
        "      !pv /content/gdrive/MyDrive/jukebox/models/5b/vqvae.pth.tar > /root/.cache/jukebox/models/5b/vqvae.pth.tar\n",
        "\n",
        "def load_1b_lyrics_level2():\n",
        "  if os.path.exists(\"/root/.cache/jukebox/models/1b_lyrics/prior_level_2.pth.tar\") == False:\n",
        "    if os.path.exists(\"/content/gdrive/MyDrive/jukebox/models/1b_lyrics/prior_level_2.pth.tar\") == False:\n",
        "      print(\"1b_lyrics_level_2 not stored in Google Drive. Downloading for the first time. This will take a few more minutes.\")\n",
        "      !wget https://openaipublic.azureedge.net/jukebox/models/1b_lyrics/prior_level_2.pth.tar -O /content/gdrive/MyDrive/jukebox/models/1b_lyrics/prior_level_2.pth.tar\n",
        "    else:\n",
        "      print(\"1b_lyrics_level_2 stored in Google Drive.\")\n",
        "    print(\"Copying 1B_Lyrics Level 2\")\n",
        "    !pv /content/gdrive/MyDrive/jukebox/models/1b_lyrics/prior_level_2.pth.tar > /root/.cache/jukebox/models/1b_lyrics/prior_level_2.pth.tar\n",
        "\n",
        "def load_5b_lyrics_level2():\n",
        "  if os.path.exists(\"/root/.cache/jukebox/models/5b_lyrics/prior_level_2.pth.tar\") == False:\n",
        "    if os.path.exists(\"/content/gdrive/MyDrive/jukebox/models/5b_lyrics/prior_level_2.pth.tar\") == False:\n",
        "      print(\"5b_lyrics_level_2 not stored in Google Drive. Downloading for the first time. This will take up to 10-15 minutes.\")\n",
        "      !wget https://openaipublic.azureedge.net/jukebox/models/5b_lyrics/prior_level_2.pth.tar -O /content/gdrive/MyDrive/jukebox/models/5b_lyrics/prior_level_2.pth.tar\n",
        "    else:\n",
        "      print(\"5b_lyrics_level_2 stored in Google Drive.\")\n",
        "    print(\"Copying 5B_Lyrics Level 2\")\n",
        "    !pv /content/gdrive/MyDrive/jukebox/models/5b_lyrics/prior_level_2.pth.tar > /root/.cache/jukebox/models/5b_lyrics/prior_level_2.pth.tar\n",
        "\n",
        "def load_5b_level1():\n",
        "  if os.path.exists('/root/.cache/jukebox/models/5b/prior_level_1.pth.tar') == False:\n",
        "    if os.path.exists(\"/content/gdrive/MyDrive/jukebox/models/5b/prior_level_1.pth.tar\") == False:\n",
        "      print(\"5b_level_1 not stored in Google Drive. Downloading for the first time. This may take a few more minutes.\")\n",
        "      !wget https://openaipublic.azureedge.net/jukebox/models/5b/prior_level_1.pth.tar -O /content/gdrive/MyDrive/jukebox/models/5b/prior_level_1.pth.tar\n",
        "    else:\n",
        "      print(\"5b_level_1 stored in Google Drive.\")\n",
        "    print(\"Copying 5B Level 1\")\n",
        "    !pv /content/gdrive/MyDrive/jukebox/models/5b/prior_level_1.pth.tar > /root/.cache/jukebox/models/5b/prior_level_1.pth.tar\n",
        "\n",
        "def load_5b_level0():\n",
        "  if os.path.exists('/root/.cache/jukebox/models/5b/prior_level_0.pth.tar') == False:\n",
        "    if os.path.exists(\"/content/gdrive/MyDrive/jukebox/models/5b/prior_level_0.pth.tar\") == False:\n",
        "      print(\"5b_level_0 not stored in Google Drive. Downloading for the first time. This may take a few minutes.\")\n",
        "      !wget https://openaipublic.azureedge.net/jukebox/models/5b/prior_level_0.pth.tar -O /content/gdrive/MyDrive/jukebox/models/5b/prior_level_0.pth.tar\n",
        "    else:\n",
        "      print(\"5b_level_0 stored in Google Drive.\")\n",
        "    print(\"Copying 5B Level 0\")\n",
        "    !pv /content/gdrive/MyDrive/jukebox/models/5b/prior_level_0.pth.tar > /root/.cache/jukebox/models/5b/prior_level_0.pth.tar\n",
        "\n",
        "def load_5b_level2():\n",
        "  if os.path.exists('/root/.cache/jukebox/models/5b/prior_level_2.pth.tar') == False:\n",
        "    if os.path.exists(\"/content/gdrive/MyDrive/jukebox/models/5b/prior_level_2.pth.tar\") == False:\n",
        "      print(\"5b_level_2 not stored in Google Drive. Downloading for the first time. This will take up to 10-15 minutes.\")\n",
        "      !wget https://openaipublic.azureedge.net/jukebox/models/5b/prior_level_2.pth.tar -O /content/gdrive/MyDrive/jukebox/models/5b/prior_level_2.pth.tar\n",
        "    else:\n",
        "      print(\"5b_level_2 stored in Google Drive.\")\n",
        "  print(\"Copying 5B Level 2\")\n",
        "  !pv /content/gdrive/MyDrive/jukebox/models/5b/prior_level_2.pth.tar > /root/.cache/jukebox/models/5b/prior_level_2.pth.tar\n",
        "\n",
        "if save_and_load_models_from_drive == True:\n",
        "  if model == '5b_lyrics':\n",
        "    load_5b_vqvae()\n",
        "    load_5b_lyrics_level2()\n",
        "    load_5b_level1()\n",
        "    load_5b_level0()\n",
        "  if model == '5b':\n",
        "    load_5b_vqvae()\n",
        "    load_5b_level2()\n",
        "    load_5b_level1()\n",
        "    load_5b_level0()\n",
        "  elif model == '1b_lyrics':\n",
        "    load_5b_vqvae()\n",
        "    load_1b_lyrics_level2()\n",
        "    load_5b_level1()\n",
        "    load_5b_level0()\n",
        "#END GDRIVE MODEL LOADER\n",
        "\n",
        "hps = Hyperparams()\n",
        "hps.sr = 44100\n",
        "hps.n_samples =  2#@param {type:\"integer\"}\n",
        "# Specifies the directory to save the sample in.\n",
        "# We set this to the Google Drive mount point.\n",
        "hps.name = '/content/gdrive/MyDrive/musicAI/musicAI20' #@param {type:\"string\"}\n",
        "chunk_size = 16 if model in ('5b', '5b_lyrics') else 32\n",
        "gpu_info = !nvidia-smi -L\n",
        "if gpu_info[0].find('Tesla T4') >= 0:\n",
        "  max_batch_size = 2\n",
        "  print('Tesla T4 detected, max_batch_size set to 2')\n",
        "elif gpu_info[0].find('Tesla K80') >= 0:\n",
        "  max_batch_size = 8\n",
        "  print('Tesla K80 detected, max_batch_size set to 8')\n",
        "elif gpu_info[0].find('Tesla P100') >= 0:\n",
        "  max_batch_size = 3\n",
        "  print('Tesla P100 detected, max_batch_size set to 3')\n",
        "elif gpu_info[0].find('Tesla V100') >= 0:\n",
        "  max_batch_size = 3\n",
        "  print('Tesla V100 detected, max_batch_size set to 3')\n",
        "else:\n",
        "  max_batch_size = 3\n",
        "  print('Different GPU detected, max_batch_size set to 3.')\n",
        "hps.levels = 3\n",
        "speed_upsampling = False #@param {type: \"boolean\"}\n",
        "if speed_upsampling == True:\n",
        "  hps.hop_fraction = [1,1,.125]\n",
        "else:\n",
        "  hps.hop_fraction = [.5,.5,.125]\n",
        "\n",
        "vqvae, *priors = MODELS[model]\n",
        "vqvae = make_vqvae(setup_hparams(vqvae, dict(sample_length = 1048576)), device)\n",
        "top_prior = make_prior(setup_hparams(priors[-1], dict()), vqvae, device)\n",
        "\n",
        "# The default mode of operation.\n",
        "# Creates songs based on artist and genre conditioning.\n",
        "mode = 'primed' #@param [\"ancestral\", \"primed\"]\n",
        "if mode == 'ancestral':\n",
        "  codes_file=None\n",
        "  audio_file=None\n",
        "  prompt_length_in_seconds=None\n",
        "if mode == 'primed':\n",
        "  codes_file=None\n",
        "  # Specify an audio file here.\n",
        "  audio_file = '/content/gdrive/MyDrive/musicAI/Amen-break.wav' #@param {type:\"string\"}\n",
        "  # Specify how many seconds of audio to prime on.\n",
        "  prompt_length_in_seconds=6 #@param {type:\"integer\"}\n",
        "\n",
        "sample_length_in_seconds = 24 #@param {type:\"integer\"}\n",
        "\n",
        "if os.path.exists(hps.name):\n",
        "  # Identify the lowest level generated and continue from there.\n",
        "  for level in [0, 1, 2]:\n",
        "    data = f\"{hps.name}/level_{level}/data.pth.tar\"\n",
        "    if os.path.isfile(data):\n",
        "      codes_file = data\n",
        "      if int(sample_length_in_seconds) > int(librosa.get_duration(filename=f'{hps.name}/level_2/item_0.wav')):\n",
        "        mode = 'continue'\n",
        "      else:\n",
        "        mode = 'upsample'\n",
        "      break\n",
        "\n",
        "print('mode is now '+mode)\n",
        "if mode == 'continue':\n",
        "  print('Continuing from level 2')\n",
        "if mode == 'upsample':\n",
        "  print('Upsampling from level '+str(level))\n",
        "\n",
        "sample_hps = Hyperparams(dict(mode=mode, codes_file=codes_file, audio_file=audio_file, prompt_length_in_seconds=prompt_length_in_seconds))\n",
        "\n",
        "if mode == 'upsample':\n",
        "  sample_length_in_seconds=int(librosa.get_duration(filename=f'{hps.name}/level_{level}/item_0.wav'))\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zs = [z.cpu() for z in data['zs']]\n",
        "  hps.n_samples = zs[-1].shape[0]\n",
        "\n",
        "if mode == 'continue':\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zs = [z.cpu() for z in data['zs']]\n",
        "  hps.n_samples = zs[-1].shape[0]\n",
        "\n",
        "hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "assert hps.sample_length >= top_prior.n_ctx*top_prior.raw_to_tokens, f'Please choose a larger sampling rate'\n",
        "\n",
        "# Note: Metas can contain different prompts per sample.\n",
        "# By default, all samples use the same prompt.\n",
        "\n",
        "select_artist = \"pink_floyd\" #@param {type:\"string\"}\n",
        "select_genre = \"psychedelic\" #@param {type:\"string\"}\n",
        "metas = [dict(artist = select_artist,\n",
        "            genre = select_genre,\n",
        "            total_length = hps.sample_length,\n",
        "            offset = 0,\n",
        "            lyrics = your_lyrics, \n",
        "            ),\n",
        "          ] * hps.n_samples\n",
        "labels = [None, None, top_prior.labeller.get_batch_labels(metas, 'cuda')]\n",
        "\n",
        "sampling_temperature = .96 #@param {type:\"number\"}\n",
        "\n",
        "if gpu_info[0].find('Tesla T4') >= 0:\n",
        "  lower_batch_size = 12\n",
        "  print('Tesla T4 detected, lower_batch_size set to 12')\n",
        "elif gpu_info[0].find('Tesla K80') >= 0:\n",
        "  lower_batch_size = 8\n",
        "  print('Tesla K80 detected, lower_batch_size set to 8')\n",
        "elif gpu_info[0].find('Tesla P100') >= 0:\n",
        "  lower_batch_size = 16\n",
        "  print('Tesla P100 detected, lower_batch_size set to 16')\n",
        "elif gpu_info[0].find('Tesla V100') >= 0:\n",
        "  lower_batch_size = 16\n",
        "  print('Tesla V100 detected, lower_batch_size set to 16')\n",
        "else:\n",
        "  lower_batch_size = 8\n",
        "  print('Different GPU detected, lower_batch_size set to 8.')\n",
        "lower_level_chunk_size = 32\n",
        "chunk_size = 16 if model in ('5b', '5b_lyrics') else 32\n",
        "sampling_kwargs = [dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                        chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=0.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                         chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=sampling_temperature, fp16=True, \n",
        "                         max_batch_size=max_batch_size, chunk_size=chunk_size)]\n",
        "\n",
        "if sample_hps.mode == 'ancestral':\n",
        "  zs = [t.zeros(hps.n_samples,0,dtype=t.long, device='cpu') for _ in range(len(priors))]\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "elif sample_hps.mode == 'upsample':\n",
        "  assert sample_hps.codes_file is not None\n",
        "  # Load codes.\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zs = [z.cpu() for z in data['zs']]\n",
        "  assert zs[-1].shape[0] == hps.n_samples, f\"Expected bs = {hps.n_samples}, got {zs[-1].shape[0]}\"\n",
        "  del data\n",
        "  print('One click upsampling!')\n",
        "elif sample_hps.mode == 'primed':\n",
        "  assert sample_hps.audio_file is not None\n",
        "  audio_files = sample_hps.audio_file.split(',')\n",
        "  duration = (int(sample_hps.prompt_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "  x = load_prompts(audio_files, duration, hps)\n",
        "  zs = top_prior.encode(x, start_level=0, end_level=len(priors), bs_chunks=x.shape[0])\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "elif sample_hps.mode == 'continue':\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zs = [z.cuda() for z in data['zs']]\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "else:\n",
        "  raise ValueError(f'Unknown sample mode {sample_hps.mode}.')\n",
        "\n",
        "# Set this False if you are on a local machine that has enough memory (this allows you to do the\n",
        "# lyrics alignment visualization during the upsampling stage). For a hosted runtime, \n",
        "# we'll need to go ahead and delete the top_prior if you are using the 5b_lyrics model.\n",
        "if True:\n",
        "  del top_prior\n",
        "  empty_cache()\n",
        "  top_prior=None\n",
        "upsamplers = [make_prior(setup_hparams(prior, dict()), vqvae, 'cpu') for prior in priors[:-1]]\n",
        "labels[:2] = [prior.labeller.get_batch_labels(metas, 'cuda') for prior in upsamplers]\n",
        "\n",
        "zs = upsample(zs, labels, sampling_kwargs, [*upsamplers, top_prior], hps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsylUKVtW71G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCSxNemzcMxN"
      },
      "source": [
        "# Guide to the above settings:\n",
        "\n",
        "**your_lyrics:** Specify the lyrics Jukebox should attempt to follow. You can paste any lyrics you want in here or leave it blank, which will result in gibberish.\n",
        "\n",
        "**model:**\n",
        "OpenAI has trained a few different models for Jukebox. In this notebook, you can access the 5b_lyrics, 5b and 1b_lyrics models. As you can imagine, the 5b_lyrics model is the superior one, but also requires a stronger GPU to run properly. Which model you should choose depends on the GPU you were assigned, which you can check in the first cell of the notebook. Recommended settings: 5b_lyrics on P100 or T4 GPU, 1b_lyrics on K80 GPU.\n",
        "(5b_lyrics theoretically works on a K80 now, but sampling is going to be super slow.)\n",
        "\n",
        "(5b is like 5b_lyrics, without supporting custom lyrics, so it will generate gibberish lyrics)\n",
        "\n",
        "**hps.n_samples:**\n",
        "Here you can choose how many samples you want to generate. Different GPUs can handle a different amount of samples. Recommended settings:\n",
        "P100 GPU: 3 samples,\n",
        "T4 GPU: 2 samples;\n",
        "K80 GPU: up to 8 samples, but 1b_lyrics only.\n",
        "\n",
        "**hps.name:** Specifies the name of the folder in Google Drive, where you will find your results in. Make sure to choose a different name for each of your runs, or else the notebook will get confused.\n",
        "\n",
        "**speed_upsampling:** If selected, will upsample much faster, at the cost of the samples sounding slightly \"choppy\". \n",
        "\n",
        "**mode:** Available modes are primed and ancestral. Primed will continue an already existing song, ancestral generates a song from scratch. (Upsample mode will be selected automatically if a data file is detected within the folder provided)\n",
        "\n",
        "**audio_file:** Only needed for primed mode. Specifies which song Jukebox will continue. Upload the file you want (preferred .wav format, but mp3 is supported as well) to the root directory of your Google Drive and fill in its name above.\n",
        "\n",
        "**prompt_length_in_seconds:** Only needed for primed mode. Specifies how many seconds of your file Jukebox will be primed on (so, at which point Jukebox  will \"kick in\"). Recommended to keep below 24 seconds for memory reasons.\n",
        "\n",
        "**sample_length_in_seconds:** Specifies how long your fully generated samples are going to be.\n",
        "\n",
        "**select_artist and select_genre:** List of available artists and genres can be found here: https://github.com/openai/jukebox/tree/master/jukebox/data/ids\n",
        "The 5b_lyrics (and 5b) model utilizes the v2 lists, the 1b_lyrics model the v3 lists. It is possible to combine up to five v2 genres, for example \"Hip Hop Pop Punk Disco\". Combining v3 genres is not possible.\n",
        "\n",
        "**sampling_temperature:** Determines the creativity and energy of Jukebox. The higher the temperature, the more chaotic and intense the result will be. You can experiment with this. Recommended to keep between .96 and .999"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu12YwYVDbJ3"
      },
      "source": [
        "Important links:\n",
        "\n",
        "Official blog: https://openai.com/blog/jukebox/\n",
        "Original repo: https://github.com/openai/jukebox/\n",
        "\n",
        "License: Non-commercial, for details see: https://github.com/openai/jukebox/blob/master/LICENSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyZuwKywmXsn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}